{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os , csv\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import DataPreprocessing as spike_process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load desired data from 1 session 1 animal\n",
    "# Note that there are 340 trials in 1 session\n",
    "# (For more info https://github.com/nsteinme/steinmetz-et-al-2019/wiki/data-files)\n",
    "\n",
    "data_path = '/Users/ChiaXinWei/Documents/Connected_lizards/Steinmetz/Richards_2017-10-31'\n",
    "\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load(data_path+'/'+'trials.goCue_times.npy') \n",
    "trials_response_choice = np.load(data_path+'/'+'trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load(data_path+'/'+'spontaneous.intervals.npy')\n",
    "trials_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "site_positions = np.load(data_path+'/'+'channels.sitePositions.npy')\n",
    "clusters_depths = np.load(data_path+'/'+'clusters.depths.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "channel_sites = np.load(data_path+'/'+'channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv(data_path+'/'+'channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load(data_path+'/'+'clusters.probes.npy')\n",
    "channels_probe = np.load(data_path+'/'+'channels.probe.npy')\n",
    "trials_visual_time = np.load(data_path+'/'+'trials.visualStim_times.npy')\n",
    "trial_feedback_time = np.load(data_path+'/'+'trials.feedback_times.npy')\n",
    "trial_feedback_type = np.load(data_path+'/'+'trials.feedbackType.npy')\n",
    "trial_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "\n",
    "visual_times = trials_visual_time\n",
    "# Behaviour data\n",
    "\n",
    "wheel_movement = np.load(data_path+'/'+'wheelMoves.type.npy')\n",
    "wheel_intervals = np.load(data_path+'/'+'wheelMoves.intervals.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising spikes and behaviour data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dT = 2.5\n",
    "T0 = .5\n",
    "bin_size = 100\n",
    "dt = bin_size/1000\n",
    "\n",
    "mid_brain_circuits=['SCs','SCm','MRN','APN','PAG','ZI']\n",
    "frontal_circuits=['MOs','PL','ILA','ORB','MOp','SSp']\n",
    "\n",
    "# Get neural activity data\n",
    "good_cells, brain_regions ,br = spike_process.get_good_cells(data_path) # Get brain regions\n",
    "spike_time_binned, spike_time_cells, cell_spikes_max = spike_process.bin_spikes(spike_times,spike_clusters,clusters_annotation,bin_size)\n",
    "# spike_time_binned_trial, spike_time_binned_trial_response = spike_process.sort_cells_trials(spike_time_binned, spike_time_cells, trials_intervals,trials_visual_time, epoch_duration = 2000,10)\n",
    "spike_time_binned_trial, pre_stim_spike_time_binned_trial, post_stim_spike_time_binned_trial, post_go_cue_spike_time_binned_trial, post_reward_spike_time_binned_trial = spike_process.sort_cells_behaviour_trials(spike_time_binned,spike_time_cells,trials_intervals, trials_visual_time,trials_gocue_times,trial_feedback_time, bin_size)\n",
    "\n",
    "# Sort cells into left, right and no_response trial types\n",
    "# Input behaviour phase that you want to analyse\n",
    "input_spike_behaviour_period = post_stim_spike_time_binned_trial\n",
    "left_spike_time_response, right_spike_time_response, no_response_spike_time_response = spike_process.sort_cells_trial_types(input_spike_behaviour_period,trials_intervals,spike_time_cells,trials_response_choice)\n",
    "\n",
    "# Midbrain cells\n",
    "midbrain_left_spike = spike_process.sort_cells_brain_regions(left_spike_time_response, brain_regions, clusters_annotation, mid_brain_circuits)\n",
    "midbrain_right_spike = spike_process.sort_cells_brain_regions(right_spike_time_response, brain_regions, clusters_annotation, mid_brain_circuits)\n",
    "midbrain_no_response_spike = spike_process.sort_cells_brain_regions(no_response_spike_time_response, brain_regions, clusters_annotation, mid_brain_circuits)\n",
    "midbrain_concat_left_spike_times = spike_process.concat_trials_2_timeseries(midbrain_left_spike)\n",
    "midbrain_concat_right_spike_times = spike_process.concat_trials_2_timeseries(midbrain_right_spike)\n",
    "midbrain_concat_no_response_spike_times = spike_process.concat_trials_2_timeseries(midbrain_no_response_spike)\n",
    "\n",
    "# Forebrain cells\n",
    "forebrain_left_spike = spike_process.sort_cells_brain_regions(left_spike_time_response, brain_regions, clusters_annotation, frontal_circuits)\n",
    "forebrain_right_spike = spike_process.sort_cells_brain_regions(right_spike_time_response, brain_regions, clusters_annotation, frontal_circuits)\n",
    "forebrain_no_response_spike = spike_process.sort_cells_brain_regions(no_response_spike_time_response, brain_regions, clusters_annotation, frontal_circuits)\n",
    "forebrain_concat_left_spike_times = spike_process.concat_trials_2_timeseries(forebrain_left_spike)\n",
    "forebrain_concat_right_spike_times = spike_process.concat_trials_2_timeseries(forebrain_right_spike)\n",
    "forebrain_concat_no_response_spike_times = spike_process.concat_trials_2_timeseries(forebrain_no_response_spike)\n",
    "\n",
    "# Get behaviour data\n",
    "wheel, wheel_times = spike_process.get_wheel(data_path)\n",
    "wheel_position = spike_process.wpsth(wheel, wheel_times,visual_times-T0, dT, dt)\n",
    "left_concat_wheel_position, right_concat_wheel_position, no_response_concat_wheel_position = spike_process.concat_behaviour_2_timeseries(wheel_position, trials_response_choice,epoch_duration = 500 ,bin_size = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Activity - Activity pairwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions used for calculating pairwise corr coefficient\n",
    "# (TO FIX: Remove the other half of the cartesian matrix. Currently pairwise correlation coefficient are repeated twice)\n",
    "\n",
    "def find_above_proportion(all_corr_coef, threshold = 0.1):\n",
    "    total_cells = np.sum(all_corr_coef >= threshold)\n",
    "    return round(total_cells/len(all_corr_coef),3)\n",
    "def find_below_proportion(all_corr_coef, threshold = 0.1):\n",
    "    total_cells = np.sum(all_corr_coef <= -threshold)\n",
    "    return round(total_cells/len(all_corr_coef),3)\n",
    "\n",
    "def pairwise_corrcoeff(spike_time, input_region_a,input_region_b):\n",
    "    region_a_spikes = spike_process.concat_trials_2_timeseries(spike_process.sort_cells_brain_regions(spike_time, brain_regions, clusters_annotation, input_region_a))\n",
    "    region_b_spikes = spike_process.concat_trials_2_timeseries(spike_process.sort_cells_brain_regions(spike_time, brain_regions, clusters_annotation, input_region_b))\n",
    "    \n",
    "    # Get cartesian product of indices\n",
    "    all_corr_coeff = np.array([])\n",
    "    cartesian_matrix = np.transpose([np.tile(np.arange(len(region_a_spikes)), len(region_b_spikes)), np.repeat(np.arange(len(region_b_spikes)), len(region_a_spikes))])\n",
    "    cartesian_matrix = np.transpose([np.tile(np.arange(len(region_a_spikes)), len(region_b_spikes)), np.repeat(np.arange(len(region_b_spikes)), len(region_a_spikes))])\n",
    "\n",
    "    for i in np.arange(len(cartesian_matrix)):\n",
    "        \n",
    "        # If cell == 'PAG' and cell # == 31, ignore it\n",
    "        if ( (input_region_a == ['PAG'] or input_region_b == ['PAG']) and (cartesian_matrix[i][0] == 31 or cartesian_matrix[i][1] == 31) ):\n",
    "            continue\n",
    "        \n",
    "        corr_coeff = np.corrcoef( stats.zscore(region_a_spikes[cartesian_matrix[i][0]]) , stats.zscore(region_b_spikes[cartesian_matrix[i][1]]) )\n",
    "        all_corr_coeff = np.append(all_corr_coeff,corr_coeff[0,1])\n",
    "    print('Number of cells: ',len(region_a_spikes), len(region_b_spikes), 'Number of pairwise comparisons', len(cartesian_matrix),'Median ', round(np.nanmedian(all_corr_coeff),4) )\n",
    "    \n",
    "    proportion_cells_above_threshold = np.array([])\n",
    "    proportion_cells_above_threshold = find_above_proportion(all_corr_coeff,threshold)\n",
    "    proportion_cells_below_threshold = np.array([])\n",
    "    proportion_cells_below_threshold = find_below_proportion(all_corr_coeff,threshold)\n",
    "    comparison_pairing = input_region_a + input_region_b\n",
    "    \n",
    "    return all_corr_coeff, proportion_cells_above_threshold, proportion_cells_below_threshold, comparison_pairing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysing  ['SCs', 'MOs']\n",
      "Number of cells:  73 69 Number of pairwise comparisons 5037 Median  -0.0028\n",
      "analysing  ['SCm', 'MOs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChiaXinWei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \"\"\"\n",
      "/Users/ChiaXinWei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in less_equal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells:  56 69 Number of pairwise comparisons 3864 Median  -0.0093\n",
      "analysing  ['MRN', 'MOs']\n",
      "Number of cells:  23 69 Number of pairwise comparisons 1587 Median  -0.0096\n",
      "analysing  ['PAG', 'MOs']\n",
      "Number of cells:  41 69 Number of pairwise comparisons 2829 Median  -0.0103\n",
      "analysing  ['SCs', 'ORB']\n",
      "Number of cells:  73 153 Number of pairwise comparisons 11169 Median  -0.0119\n",
      "analysing  ['SCm', 'ORB']\n",
      "Number of cells:  56 153 Number of pairwise comparisons 8568 Median  -0.0099\n",
      "analysing  ['MRN', 'ORB']\n",
      "Number of cells:  23 153 Number of pairwise comparisons 3519 Median  -0.0086\n",
      "analysing  ['PAG', 'ORB']\n",
      "Number of cells:  41 153 Number of pairwise comparisons 6273 Median  -0.01\n"
     ]
    }
   ],
   "source": [
    "# Activity - Activity correlation between region A and B.\n",
    "\n",
    "# We can perform mean-matching first to ensure that the distribution is the same.\n",
    "# E.g. region A and B have the same number of neurons. Churchland et al., 2010\n",
    "\n",
    "# Set threshold for testing proportion of cells that lie above or below\n",
    "threshold = 0.1\n",
    "\n",
    "# Plot and run all input brain regions for pairwise correlation coefficient\n",
    "mid_brain_circuits=['SCs','SCm','MRN','PAG']\n",
    "frontal_circuits=['MOs','ORB']\n",
    "cartesian_matrix_plot = np.transpose([np.tile(np.arange(len(mid_brain_circuits)), len(frontal_circuits)), np.repeat(np.arange(len(frontal_circuits)), len(mid_brain_circuits))])\n",
    "combined_corr_coeff = np.empty(len(cartesian_matrix_plot), dtype=object) # Initalise empty object\n",
    "proportion_above_threshold = np.empty(len(cartesian_matrix_plot), dtype=object) # Initalise empty object\n",
    "proportion_below_threshold = np.empty(len(cartesian_matrix_plot), dtype=object) # Initalise empty object\n",
    "comparison_pairing = np.empty(len(cartesian_matrix_plot), dtype=object) # Initalise empty object\n",
    "\n",
    "for plot_num in np.arange(len(cartesian_matrix_plot)):\n",
    "    input_region_a = [mid_brain_circuits[cartesian_matrix_plot[plot_num][0]]]\n",
    "    input_region_b = [frontal_circuits[cartesian_matrix_plot[plot_num][1]]]\n",
    "    print('analysing ', input_region_a + input_region_b)\n",
    "    # Get correlation coef\n",
    "    combined_corr_coeff[plot_num], proportion_above_threshold[plot_num],proportion_below_threshold[plot_num], comparison_pairing[plot_num]  = pairwise_corrcoeff(right_spike_time_response, input_region_a,input_region_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms of all pairwise corr coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bin = 100\n",
    "save_data_path = '/Users/ChiaXinWei/Documents/Connected_lizards/Draft_figures'\n",
    "\n",
    "plt.figure(figsize=(3,4))\n",
    "fig, axs = plt.subplots(4, 2,figsize=(10,10), sharex='col', sharey='row',\n",
    "                        gridspec_kw={'hspace': 0.3, 'wspace': 0.1})\n",
    "(ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8) = axs\n",
    "fig.suptitle('Pairwise comparisons between regions for post-stim trial duration | Proportion threshold= '+ str(threshold)+ ' | Spike bin size: ' + str(bin_size) )\n",
    "\n",
    "# Plot histograms of all region comparisons\n",
    "\n",
    "ax1.hist(combined_corr_coeff[1], hist_bin)\n",
    "step = 0\n",
    "ax1.set_xlim([-0.2,0.2])\n",
    "ax1.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax2.hist(combined_corr_coeff[1], hist_bin)\n",
    "step = 1\n",
    "ax2.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax3.hist(combined_corr_coeff[2], hist_bin)\n",
    "step = 2\n",
    "ax3.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax4.hist(combined_corr_coeff[3], hist_bin)\n",
    "step = 3\n",
    "ax4.set_xlim([-0.2,0.2])\n",
    "ax4.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax5.hist(combined_corr_coeff[4], hist_bin)\n",
    "step = 4\n",
    "ax5.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax6.hist(combined_corr_coeff[5], hist_bin)\n",
    "step = 5\n",
    "ax6.set_xlim()\n",
    "ax6.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax7.hist(combined_corr_coeff[6], hist_bin)\n",
    "step = 6\n",
    "ax7.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "ax8.hist(combined_corr_coeff[7], hist_bin)\n",
    "step = 7\n",
    "ax8.set_title(comparison_pairing[step]+ [proportion_above_threshold[step]]+ [proportion_below_threshold[step]] )\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.savefig(save_data_path+'/'+\"hist_corr_coeff_righttrials_poststim.eps\")\n",
    "plt.savefig(save_data_path+'/'+\"hist_corr_coeff_righttrials_poststim.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_region_a = ['SCs']\n",
    "input_region_b = ['SCs']\n",
    "plt.figure(0)\n",
    "corr_coef = pairwise_corrcoeff(right_spike_time_response, input_region_a,input_region_b)\n",
    "plt.hist(corr_coef,100)\n",
    "plt.xlim([-0.2,0.2])\n",
    "plt.title(input_region_a + input_region_b + [str(find_proportion(corr_coef))] )\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.show\n",
    "\n",
    "input_region_a = ['SCs']\n",
    "input_region_b = ['MOs']\n",
    "print(np.sum(brain_regions == input_region_a))\n",
    "plt.figure(1)\n",
    "corr_coef = pairwise_corrcoeff(right_spike_time_response, input_region_a,input_region_b)\n",
    "plt.hist(corr_coef,100)\n",
    "plt.xlim([-0.2,0.2])\n",
    "plt.title(input_region_a + input_region_b +[str(find_proportion(corr_coef))] )\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform some quick visualisation on the spike and behaviour data\n",
    "\n",
    "plt.figure(0)\n",
    "cell_num = 42\n",
    "plt.plot(midbrain_concat_left_spike_times[cell_num])\n",
    "plt.title('Spikes for 1 cell across session (10ms bin)')\n",
    "plt.show\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(left_concat_wheel_position)\n",
    "plt.title('Wheel position across session')\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression analysis\n",
    "\n",
    "corr_coeff = np.array([])\n",
    "for cell_num in np.arange(len(midbrain_concat_left_spike_times)):\n",
    "    corr_coeff = np.append(corr_coeff,np.corrcoef(midbrain_concat_left_spike_times[cell_num], left_concat_wheel_position)[0,1])\n",
    "\n",
    "plt.figure(0)\n",
    "plt.hist(corr_coeff,bins = 20)\n",
    "plt.title('Midbrain Correlation Coeff with Wheel')\n",
    "plt.xlim((-0.08, 0.08))\n",
    "plt.show\n",
    "\n",
    "corr_coeff = np.array([])\n",
    "for cell_num in np.arange(len(forebrain_concat_left_spike_times)):\n",
    "    corr_coeff = np.append(corr_coeff,np.corrcoef(forebrain_concat_left_spike_times[cell_num], left_concat_wheel_position)[0,1])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(corr_coeff,bins = 20)\n",
    "plt.title('Forebrain Correlation Coeff with Wheel')\n",
    "plt.xlim((-0.08, 0.08))\n",
    "plt.show\n",
    "\n",
    "corr_coeff = np.array([])\n",
    "for cell_num in np.arange(len(forebrain_concat_left_spike_times)):\n",
    "    corr_coeff = np.append(corr_coeff,np.corrcoef(forebrain_concat_left_spike_times[cell_num], left_concat_wheel_position)[0,1])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(corr_coeff,bins = 20)\n",
    "plt.title('Forebrain Correlation Coeff with Wheel')\n",
    "plt.xlim((-0.08, 0.08))\n",
    "plt.show\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
