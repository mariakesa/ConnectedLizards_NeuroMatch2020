{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os , csv\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load desired data from 1 session 1 animal\n",
    "# Note that there are 340 trials in 1 session\n",
    "# (For more info https://github.com/nsteinme/steinmetz-et-al-2019/wiki/data-files)\n",
    "\n",
    "data_path = '/Users/xinweichia/Documents/connected_lizards/Steinmetz_dataset/Richards_2017-10-31'\n",
    "\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load(data_path+'/'+'trials.goCue_times.npy') \n",
    "trials_response_choice = np.load(data_path+'/'+'trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load(data_path+'/'+'spontaneous.intervals.npy')\n",
    "trials_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "site_positions = np.load(data_path+'/'+'channels.sitePositions.npy')\n",
    "clusters_depths = np.load(data_path+'/'+'clusters.depths.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "channel_sites = np.load(data_path+'/'+'channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv(data_path+'/'+'channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load(data_path+'/'+'clusters.probes.npy')\n",
    "channels_probe = np.load(data_path+'/'+'channels.probe.npy')\n",
    "trials_visual_time = np.load(data_path+'/'+'trials.visualStim_times.npy')\n",
    "\n",
    "visual_times = trials_visual_time\n",
    "# Behaviour data\n",
    "\n",
    "wheel_movement = np.load(data_path+'/'+'wheelMoves.type.npy')\n",
    "wheel_intervals = np.load(data_path+'/'+'wheelMoves.intervals.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/MouseLand/steinmetz2019_NMA/blob/master/steinmetz_loader.py\n",
    "# To obtain brain regions\n",
    "def get_good_cells(fdirpath): #\n",
    "    # location in brain of each neuron\n",
    "    brain_loc = os.path.join(fdirpath, \"channels.brainLocation.tsv\")\n",
    "\n",
    "    good_cells = (np.load(os.path.join(fdirpath, \"clusters._phy_annotation.npy\")) >= 2 ).flatten()\n",
    "    clust_channel = np.load(os.path.join(fdirpath, \"clusters.peakChannel.npy\")).astype(int) - 1\n",
    "    br = []\n",
    "    with open(brain_loc, 'r') as tsv:\n",
    "        tsvin = csv.reader(tsv, delimiter=\"\\t\")\n",
    "        k=0\n",
    "        for row in tsvin:\n",
    "            if k>0:\n",
    "                br.append(row[-1])\n",
    "            k+=1\n",
    "    br = np.array(br)\n",
    "    good_cells = np.logical_and(good_cells, clust_channel.flatten()<len(br))\n",
    "    brain_region = br[clust_channel[:,0]]\n",
    "\n",
    "\n",
    "    return good_cells, brain_region, br\n",
    "\n",
    "good_cells, brain_regions ,br = get_good_cells(data_path) # Get brain regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin cells according to input bin size\n",
    "\n",
    "def bin_spikes(spike_times, bin_size = 10):\n",
    "    \n",
    "    # Using clusters._phy_annotation.npy obtain valid clusters (i.e. >= 2)\n",
    "    valid_clusters_idx = np.array(np.where(clusters_annotation>=2))[0]\n",
    "\n",
    "    spike_time_cells = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    for i,cell_idx in enumerate(valid_clusters_idx):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == cell_idx)[0])]\n",
    "\n",
    "    # Bin spike times into 10ms intervals\n",
    "    spike_time_binned = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    sum_spikes = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "\n",
    "    for cell_num in np.arange(len(spike_time_cells)): \n",
    "        spike_time_hist = np.histogram(spike_time_cells[cell_num],bins = np.arange(0,np.floor(spike_time_cells[cell_num][-1]),bin_size))\n",
    "        spike_time_binned[cell_num] = spike_time_hist[0]\n",
    "        sum_spikes[cell_num] = np.sum(spike_time_binned[cell_num])\n",
    "\n",
    "    cell_spikes_max = np.argmax(sum_spikes) # cell with the maximum number of spikes for plotting purposes\n",
    "    \n",
    "    # Spike_time_binned returns binned spikes sorted into cells\n",
    "    # Spike_time_cells returns UNbinned spikes sorted into cells\n",
    "    # cell_spikes_max returns a single cell index that has the max number of spikes (i.e most active cell)\n",
    "    return spike_time_binned, spike_time_cells, cell_spikes_max\n",
    "\n",
    "spike_time_binned, spike_time_cells, cell_spikes_max = bin_spikes(spike_times,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260,)\n"
     ]
    }
   ],
   "source": [
    "# Sort cells into trial types and relevant epoch\n",
    "\n",
    "# (Need to change the sorting into matrices rather than vectors)\n",
    "\n",
    "def sort_cells_trials(spike_time_binned, epoch_duration = 400 , bin_size = 10):\n",
    "\n",
    "    # Epoch duration is defined as the period after the visual stimulus\n",
    "\n",
    "    # Sort into trials\n",
    "    spike_time_binned_trial = np.empty(len(spike_time_cells), dtype=object)\n",
    "    spike_time_binned_trial_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        spike_time_binned_trial[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "        spike_time_binned_trial_response[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "  \n",
    "        for i,trials_start_end in enumerate(trials_intervals):\n",
    "            # Sort spikes into their trial numbers. \n",
    "            spike_time_binned_trial[cell_num][i] = spike_time_binned[cell_num][ int(np.floor(trials_start_end[0]*(1000/bin_size))) : int(np.floor(trials_start_end[1]*(1000/bin_size)))]\n",
    "            # Using visual onset to splice a trial into visual onset : visual onset +400ms\n",
    "            spike_time_binned_trial_response[cell_num][i] = spike_time_binned[cell_num][(int(np.floor(trials_visual_time[i]*(1000/bin_size)))) : (int(np.floor(trials_visual_time[i]*(1000/bin_size)) + epoch_duration))]\n",
    "            \n",
    "    # spike_time_binned_trial returns spikes that are sorted into cells and trials\n",
    "    # spike_time_binned_trial_response returns spikes that are sorted into cells and trials, and spliced accordingly to desired epoch duration post-visual stim onset\n",
    "    \n",
    "    return spike_time_binned_trial, spike_time_binned_trial_response\n",
    "\n",
    "# Shape of spike_time_binned_trial[cell_num][trial_num][# of bins]\n",
    "\n",
    "#spike_time_binned_trial, spike_time_binned_trial_response = sort_cells_trials(spike_time_binned,40)\n",
    "spike_time_binned_trial, spike_time_binned_trial_response = sort_cells_trials(spike_time_binned,40,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591,)\n"
     ]
    }
   ],
   "source": [
    "print(spike_time_binned_trial[1][10].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort trials into 3 trial types based on argument (e.g. response_choice, feedback type), left, \n",
    "\n",
    "def sort_cells_trial_types(spike_time_binned_trial_response):\n",
    "\n",
    "    # Input: spike_time_binned_trial_response can be any spike_time_binned variable regardless of whether it has been spliced.\n",
    "\n",
    "    # Get response choice trials types\n",
    "    right_choice_trials = np.where(trials_response_choice == -1)[0]\n",
    "    left_choice_trials = np.where(trials_response_choice == 1)[0]\n",
    "    no_response_choice_trials = np.where(trials_response_choice == 0)[0]\n",
    "\n",
    "    # Sort trials into response type\n",
    "    left_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    right_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    no_response_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    \n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        left_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][left_choice_trials]\n",
    "        right_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][right_choice_trials]\n",
    "        no_response_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][no_response_choice_trials]\n",
    "    \n",
    "    # Returns 3 variables by sorting the spike_time_binned variable into left, right no response trials\n",
    "    return left_spike_time_response, right_spike_time_response, no_response_spike_time_response\n",
    "\n",
    "left_spike_time_response, right_spike_time_response, no_response_spike_time_response = sort_cells_trial_types(spike_time_binned_trial_response)\n",
    "\n",
    "# Shape of spike time response left_spike_time_response[cell_num][trial_num][# of bins in 400ms]\n",
    "# (Maybe i should change it to left_spike_time_response[cell_num][trial_num x # of bins] ?)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cells into input brain regions and merge them across all regions\n",
    "\n",
    "def sort_cells_brain_regions(spike_time_response, *input_region):\n",
    "    \n",
    "    regional_spike_time_response = np.empty(len(input_region), dtype=object)\n",
    "    for i,region in enumerate(input_region):\n",
    "        # Get brain regions that correponds to the desired region\n",
    "        brain_region_annotation = clusters_annotation[brain_regions == region]\n",
    "        # Select only valid regions i.e. annotation >=2\n",
    "        valid_brain_regions_idx = np.where(brain_region_annotation >= 2)[0]\n",
    "        # Index the spike time to get spikes from desired regions\n",
    "        regional_spike_time_response[i] = spike_time_response[valid_brain_regions_idx]\n",
    "    \n",
    "    # Merge spikes across all regions\n",
    "    merged_region_spikes = []\n",
    "    for i in np.arange(len(regional_spike_time_response)):\n",
    "        merged_region_spikes = np.append(merged_region_spikes, regional_spike_time_response[i])\n",
    "    \n",
    "    # Return spike time sorted into regions and merged across all regions\n",
    "    # Indexing: regional_spike_times[cell_num][trial_num][# of bins]\n",
    "    return merged_region_spikes\n",
    "\n",
    "mid_brain_circuits=['SCs','SCm','MRN','APN','PAG','ZI']\n",
    "frontal_circuits=['MOs','PL','ILA','ORB','MOp','SSp']\n",
    "\n",
    "regional_left_spike = sort_cells_brain_regions(left_spike_time_response, 'SCs','SCm','MRN','APN','PAG','ZI')\n",
    "regional_right_spike = sort_cells_brain_regions(right_spike_time_response, 'SCs','SCm','MRN','APN','PAG','ZI')\n",
    "regional_no_response_spike = sort_cells_brain_regions(no_response_spike_time_response, 'SCs','SCm','MRN','APN','PAG','ZI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(99,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate trial epochs into an entire time series \n",
    "# e.g. if 400ms/trial were used(260trial x 40bins will be reshaped into 1 x 10400bins\n",
    "\n",
    "def concat_trials_2_timeseries(spike_time_response):\n",
    "    concat_spike_time_response = np.empty(len(spike_time_response), dtype=object)\n",
    "    \n",
    "    for cell_num in np.arange(len(spike_time_response)):\n",
    "        concat_spike_time_response[cell_num] = np.array([])\n",
    "        for trial_num in np.arange(len(spike_time_response[cell_num])):\n",
    "            concat_spike_time_response[cell_num] = np.append(concat_spike_time_response[cell_num],(spike_time_response[cell_num][trial_num]))\n",
    "    \n",
    "    # Return concatenated spike time response \n",
    "    # Indexing: spike_times[cell_num][# of bins ]\n",
    "    return concat_spike_time_response\n",
    "\n",
    "concat_left_spike_times = concat_trials_2_timeseries(regional_left_spike)\n",
    "concat_right_spike_times = concat_trials_2_timeseries(regional_right_spike)\n",
    "concat_no_resonse_spike_times = concat_trials_2_timeseries(regional_no_response_spike)\n",
    "\n",
    "print(concat_left_spike_times[3])\n",
    "print(regional_left_spike[1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of behaviour and neural activity tallies | Shape:(3000,)\n",
      "(3960,)\n",
      "(3000,)\n",
      "(3440,)\n"
     ]
    }
   ],
   "source": [
    "# Geting behavioural data\n",
    "# Taken from https://github.com/MouseLand/steinmetz2019_NMA/blob/master/steinmetz_loader.py\n",
    "\n",
    "def get_wheel(fdirpath):\n",
    "    wheel = np.load(os.path.join(fdirpath, \"wheel.position.npy\")).flatten()\n",
    "    wheel_times = np.load(os.path.join(fdirpath,   \"wheel.timestamps.npy\"))\n",
    "    return wheel, wheel_times\n",
    "\n",
    "# Get wheel peristimulus time histogram. Aligned to the onset of visual stim.\n",
    "# (I'm assuming that the wheel trials here have T0 = Onset of visual stim. Hence it should be the aligned to our spike_times)\n",
    "def wpsth(wheel, wheel_times, etime, dT, dt):\n",
    "    ntrials = len(etime)\n",
    "    NT = int(dT/dt)\n",
    "    f = interp1d(wheel_times[:,1], wheel_times[:,0], fill_value='extrapolate')\n",
    "    S  = np.zeros((ntrials, NT))\n",
    "    for j in range(ntrials):\n",
    "        # Note that etime = visual_time onset - 0.5s\n",
    "        tsamp = f(np.arange(etime[j], etime[j]+dT+1e-5, dt)).astype('int32')\n",
    "        S[j,:] = wheel[tsamp[1:]] - wheel[tsamp[:-1]]\n",
    "    return S\n",
    "\n",
    "dt = 1/100\n",
    "dT = 2.5\n",
    "T0 = .5\n",
    "\n",
    "wheel, wheel_times = get_wheel(data_path)\n",
    "wheel_position = wpsth(wheel, wheel_times,visual_times-T0, dT, dt)\n",
    "# plt.plot(wheel_position[10])\n",
    "\n",
    "# Concatenate behaviour based on epoch we set to get same dimension as neural activity for comparison\n",
    "# (i.e. reshape matrix (260trials x 40bins) to form vector (1 x 10400bins)\n",
    "\n",
    "# left_spike_time_response, right_spike_time_response, no_response_spike_time_response = sort_cells_trial_types(spike_time_binned_trial_response)\n",
    "# Note that we have 3 trials types to sort for behaviour data too\n",
    "\n",
    "def concat_behaviour_2_timeseries(wheel_position, epoch_duration = 400 ,bin_size = 10):\n",
    "    # Get response choice trials types\n",
    "    right_choice_trials = np.where(trials_response_choice == -1)[0]\n",
    "    left_choice_trials = np.where(trials_response_choice == 1)[0]\n",
    "    no_response_choice_trials = np.where(trials_response_choice == 0)[0]\n",
    "    \n",
    "    left_concat_wheel_position = np.array([])\n",
    "    right_concat_wheel_position = np.array([])\n",
    "    no_response_concat_wheel_position = np.array([])\n",
    "    for trial_num in left_choice_trials:\n",
    "        left_concat_wheel_position = np.append(left_concat_wheel_position,wheel_position[trial_num,0:int(epoch_duration/bin_size)])\n",
    "    for trial_num in right_choice_trials:\n",
    "        right_concat_wheel_position = np.append(right_concat_wheel_position,wheel_position[trial_num,0:int(epoch_duration/bin_size)])\n",
    "    for trial_num in no_response_choice_trials:\n",
    "        no_response_concat_wheel_position = np.append(no_response_concat_wheel_position,wheel_position[trial_num,0:int(epoch_duration/bin_size)])\n",
    "        \n",
    "    return left_concat_wheel_position, right_concat_wheel_position, no_response_concat_wheel_position\n",
    "\n",
    "left_concat_wheel_position, right_concat_wheel_position, no_response_concat_wheel_position = concat_behaviour_2_timeseries(wheel_position, epoch_duration = 400 ,bin_size = 10)\n",
    "\n",
    "\n",
    "# Check if behaviour dimension tallies with neural time series\n",
    "if concat_right_spike_times[3].shape[0] == right_concat_wheel_position.shape[0]:\n",
    "    print(\"The dimensions of behaviour and neural activity tallies \" + \"| Shape:\" + str(right_concat_wheel_position.shape))\n",
    "else:\n",
    "    print(\"The dimensions is wrong\")\n",
    "    \n",
    "print(left_concat_wheel_position.shape)\n",
    "print(right_concat_wheel_position.shape)\n",
    "print(no_response_concat_wheel_position.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
