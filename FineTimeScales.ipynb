{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os , csv\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= '/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files/Richards_2017-10-31.tar'\n",
    "\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load(data_path+'/'+'trials.goCue_times.npy') \n",
    "trials_response_choice = np.load(data_path+'/'+'trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load(data_path+'/'+'spontaneous.intervals.npy')\n",
    "trials_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "site_positions = np.load(data_path+'/'+'channels.sitePositions.npy')\n",
    "clusters_depths = np.load(data_path+'/'+'clusters.depths.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "channel_sites = np.load(data_path+'/'+'channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv(data_path+'/'+'channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load(data_path+'/'+'clusters.probes.npy')\n",
    "channels_probe = np.load(data_path+'/'+'channels.probe.npy')\n",
    "trials_visual_time = np.load(data_path+'/'+'trials.visualStim_times.npy')\n",
    "\n",
    "visual_times = trials_visual_time\n",
    "# Behaviour data\n",
    "\n",
    "wheel_movement = np.load(data_path+'/'+'wheelMoves.type.npy')\n",
    "wheel_intervals = np.load(data_path+'/'+'wheelMoves.intervals.npy')\n",
    "\n",
    "# Taken from https://github.com/MouseLand/steinmetz2019_NMA/blob/master/steinmetz_loader.py\n",
    "# To obtain brain regions\n",
    "def get_good_cells(fdirpath): #\n",
    "    # location in brain of each neuron\n",
    "    brain_loc = os.path.join(fdirpath, \"channels.brainLocation.tsv\")\n",
    "\n",
    "    good_cells = (np.load(os.path.join(fdirpath, \"clusters._phy_annotation.npy\")) >= 2 ).flatten()\n",
    "    clust_channel = np.load(os.path.join(fdirpath, \"clusters.peakChannel.npy\")).astype(int) - 1\n",
    "    br = []\n",
    "    with open(brain_loc, 'r') as tsv:\n",
    "        tsvin = csv.reader(tsv, delimiter=\"\\t\")\n",
    "        k=0\n",
    "        for row in tsvin:\n",
    "            if k>0:\n",
    "                br.append(row[-1])\n",
    "            k+=1\n",
    "    br = np.array(br)\n",
    "    good_cells = np.logical_and(good_cells, clust_channel.flatten()<len(br))\n",
    "    brain_region = br[clust_channel[:,0]]\n",
    "\n",
    "\n",
    "    return good_cells, brain_region, br\n",
    "\n",
    "# Bin cells according to input bin size\n",
    "\n",
    "def bin_spikes(spike_times, bin_size = 100):\n",
    "    \n",
    "    # Using clusters._phy_annotation.npy obtain valid clusters (i.e. >= 2)\n",
    "    valid_clusters_idx = np.array(np.where(clusters_annotation>=2))[0]\n",
    "\n",
    "    spike_time_cells = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    for i,cell_idx in enumerate(valid_clusters_idx):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == cell_idx)[0])]\n",
    "\n",
    "    # Bin spike times into 10ms intervals\n",
    "    spike_time_binned = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    sum_spikes = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "\n",
    "    for cell_num in np.arange(len(spike_time_cells)): \n",
    "        spike_time_hist = np.histogram(spike_time_cells[cell_num],bins = np.arange(0,np.floor(spike_time_cells[cell_num][-1]),bin_size))\n",
    "        spike_time_binned[cell_num] = spike_time_hist[0]\n",
    "        sum_spikes[cell_num] = np.sum(spike_time_binned[cell_num])\n",
    "\n",
    "    cell_spikes_max = np.argmax(sum_spikes) # cell with the maximum number of spikes for plotting purposes\n",
    "    \n",
    "    # Spike_time_binned returns binned spikes sorted into cells\n",
    "    # Spike_time_cells returns UNbinned spikes sorted into cells\n",
    "    # cell_spikes_max returns a single cell index that has the max number of spikes (i.e most active cell)\n",
    "    return spike_time_binned, spike_time_cells, cell_spikes_max\n",
    "\n",
    "# Sort cells into trial types and relevant epoch\n",
    "\n",
    "# (Need to change the sorting into matrices rather than vectors)\n",
    "\n",
    "def sort_cells_trials(spike_time_binned,spike_time_cells, epoch_duration = 2000 , bin_size = 10):\n",
    "\n",
    "    # Epoch duration is defined as the period after the visual stimulus\n",
    "\n",
    "    # Sort into trials\n",
    "    spike_time_binned_trial = np.empty(len(spike_time_cells), dtype=object)\n",
    "    spike_time_binned_trial_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        spike_time_binned_trial[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "        spike_time_binned_trial_response[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "  \n",
    "        for i,trials_start_end in enumerate(trials_intervals):\n",
    "            # Sort spikes into their trial numbers. \n",
    "            spike_time_binned_trial[cell_num][i] = spike_time_binned[cell_num][ int(np.floor(trials_start_end[0]*(1000/bin_size))) : int(np.floor(trials_start_end[1]*(1000/bin_size)))]\n",
    "            # Using visual onset to splice a trial into visual onset : visual onset +400ms\n",
    "            spike_time_binned_trial_response[cell_num][i] = spike_time_binned[cell_num][(int(np.floor(trials_visual_time[i]*(1000/bin_size)))) : (int(np.floor(trials_visual_time[i]*(1000/bin_size)) + epoch_duration))]\n",
    "            \n",
    "    # spike_time_binned_trial returns spikes that are sorted into cells and trials\n",
    "    # spike_time_binned_trial_response returns spikes that are sorted into cells and trials, and spliced accordingly to desired epoch duration post-visual stim onset\n",
    "    \n",
    "    return spike_time_binned_trial, spike_time_binned_trial_response\n",
    "\n",
    "# Sort trials into 3 trial types based on argument (e.g. response_choice, feedback type), left, \n",
    "\n",
    "def sort_cells_trial_types(spike_time_binned_trial_response,spike_time_cells):\n",
    "\n",
    "    # Input: spike_time_binned_trial_response can be any spike_time_binned variable regardless of whether it has been spliced.\n",
    "\n",
    "    # Get response choice trials types\n",
    "    right_choice_trials = np.where(trials_response_choice == -1)[0]\n",
    "    left_choice_trials = np.where(trials_response_choice == 1)[0]\n",
    "    no_response_choice_trials = np.where(trials_response_choice == 0)[0]\n",
    "\n",
    "    # Sort trials into response type\n",
    "    left_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    right_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    no_response_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    \n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        left_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][left_choice_trials]\n",
    "        right_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][right_choice_trials]\n",
    "        no_response_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][no_response_choice_trials]\n",
    "    \n",
    "    # Returns 3 variables by sorting the spike_time_binned variable into left, right no response trials\n",
    "    return left_spike_time_response, right_spike_time_response, no_response_spike_time_response\n",
    "\n",
    "def sort_cells_brain_regions(spike_time_response, input_region,brain_regions):\n",
    "    \n",
    "    regional_spike_time_response = np.empty(len(input_region), dtype=object)\n",
    "    for i,region in enumerate(input_region):\n",
    "        # Get brain regions that correponds to the desired region\n",
    "        brain_region_annotation = clusters_annotation[brain_regions == region]\n",
    "        # Select only valid regions i.e. annotation >=2\n",
    "        valid_brain_regions_idx = np.where(brain_region_annotation >= 2)[0]\n",
    "        # Index the spike time to get spikes from desired regions\n",
    "        regional_spike_time_response[i] = spike_time_response[valid_brain_regions_idx]\n",
    "    \n",
    "    # Merge spikes across all regions\n",
    "    merged_region_spikes = []\n",
    "    for i in np.arange(len(regional_spike_time_response)):\n",
    "        merged_region_spikes = np.append(merged_region_spikes, regional_spike_time_response[i])\n",
    "    \n",
    "    # Return spike time sorted into regions and merged across all regions\n",
    "    # Indexing: regional_spike_times[cell_num][trial_num][# of bins]\n",
    "    return merged_region_spikes\n",
    "\n",
    "mid_brain_circuits=['SCs','SCm','MRN','APN','PAG','ZI']\n",
    "frontal_circuits=['MOs','PL','ILA','ORB','MOp','SSp']\n",
    "#all_dat='MOs', 'MRN', 'OLF', 'ORB', 'PAG', 'RSP', 'SCm', 'SCs'\n",
    "\n",
    "# Concatenate trial epochs into an entire time series \n",
    "# e.g. if 400ms/trial were used(260trial x 400bins will be reshaped into 1 x 104 000bins\n",
    "\n",
    "def concat_trials_2_timeseries(spike_time_response):\n",
    "    concat_spike_time_response = np.empty(len(spike_time_response), dtype=object)\n",
    "    \n",
    "    for cell_num in np.arange(len(spike_time_response)):\n",
    "        concat_spike_time_response[cell_num] = np.empty(1, dtype=object)\n",
    "        for trial_num in np.arange(len(spike_time_response[cell_num])):\n",
    "            concat_spike_time_response[cell_num] = np.append(concat_spike_time_response[cell_num],(spike_time_response[cell_num][trial_num]))\n",
    "    \n",
    "    # Return concatenated spike time response \n",
    "    # Indexing: spike_times[cell_num][# of bins ]\n",
    "    return concat_spike_time_response\n",
    "\n",
    "def reshape_concat(concat_spike_times):\n",
    "    concat_spike_times_=[]\n",
    "    for j in range(0,concat_spike_times.shape[0]):\n",
    "        concat_spike_times_.append(concat_spike_times[j][1:10000])\n",
    "    concat_spike_times_=np.array(concat_spike_times_)\n",
    "    return concat_spike_times_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_left_right_PCA(bs,input_regions):\n",
    "    good_cells, brain_regions,br = get_good_cells(data_path) # Get brain regions\n",
    "    spike_time_binned, spike_time_cells, cell_spikes_max = bin_spikes(spike_times,bin_size=bs)\n",
    "    spike_time_binned_trial_response, test = sort_cells_trials(spike_time_binned,spike_time_cells,bin_size=bs)\n",
    "    \n",
    "    left_spike_time_response, right_spike_time_response, no_response_spike_time_response = sort_cells_trial_types(spike_time_binned_trial_response,spike_time_cells)\n",
    "\n",
    "\n",
    "    regional_left_spike = sort_cells_brain_regions(left_spike_time_response, input_regions,brain_regions)#'SCm','MRN','APN','PAG','ZI')\n",
    "    regional_right_spike=sort_cells_brain_regions(right_spike_time_response,input_regions,brain_regions)#'SCm','MRN','APN','PAG','ZI')\n",
    "    concat_left_spike_times = concat_trials_2_timeseries(regional_left_spike)\n",
    "    concat_right_spike_times=concat_trials_2_timeseries(regional_right_spike)\n",
    "\n",
    "    concat_left_spike_times_ = reshape_concat(concat_left_spike_times)\n",
    "    concat_right_spike_times_=reshape_concat(concat_right_spike_times)\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "\n",
    "    #left=gaussian_filter(concat_left_spike_times_, sigma=1)\n",
    "    #pritn(left.shape)\n",
    "    left_p=PCA(n_components=10)\n",
    "    right_p=PCA(n_components=10)\n",
    "\n",
    "\n",
    "    left_pcs=left_p.fit_transform(concat_left_spike_times_.T)\n",
    "    right_pcs=right_p.fit_transform(concat_right_spike_times_.T)\n",
    "\n",
    "    plt.scatter(left_pcs[:,0],left_pcs[:,1],color='orange',label='left')\n",
    "    plt.scatter(right_pcs[:,0],right_pcs[:,1],color='blue',label='right')\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine time scale binning, 10 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole brain: 'MOs', 'MRN', 'OLF', 'ORB', 'PAG', 'RSP', 'SCm', 'SCs'\n",
    "#midbrain 'SCs','SCm','MRN','APN','PAG','ZI'\n",
    "#frontal 'MOs','PL','ILA','ORB','MOp','SSp'\n",
    "\n",
    "plot_left_right_PCA(10,['MOs', 'MRN', 'OLF', 'ORB', 'PAG', 'RSP', 'SCm', 'SCs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
