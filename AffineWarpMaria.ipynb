{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affinewarp import PiecewiseWarping, SpikeData\n",
    "import numpy as np\n",
    "from affinewarp.visualization import rasters    \n",
    "import matplotlib.pyplot as plt\n",
    "from DataPreprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_brain_circuits=['SCs','SCm','MRN','APN','PAG','ZI']\n",
    "frontal_circuits=['MOs','PL','ILA','ORB','MOp','SSp']\n",
    "all_data_path='/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "data_path= '/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files/Richards_2017-10-31.tar'\n",
    "\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load(data_path+'/'+'trials.goCue_times.npy') \n",
    "trials_response_choice = np.load(data_path+'/'+'trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load(data_path+'/'+'spontaneous.intervals.npy')\n",
    "trials_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "site_positions = np.load(data_path+'/'+'channels.sitePositions.npy')\n",
    "clusters_depths = np.load(data_path+'/'+'clusters.depths.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "channel_sites = np.load(data_path+'/'+'channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv(data_path+'/'+'channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load(data_path+'/'+'clusters.probes.npy')\n",
    "channels_probe = np.load(data_path+'/'+'channels.probe.npy')\n",
    "trials_visual_time = np.load(data_path+'/'+'trials.visualStim_times.npy')\n",
    "\n",
    "good_cells, brain_regions,br = get_good_cells(data_path) #\n",
    "#print(good_cells)\n",
    "\n",
    "def get_neurons(spike_times,spike_clusters):\n",
    "    spike_time_cells = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "    for i in range(len(np.unique(spike_clusters))):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == i)[0])]\n",
    "    return spike_time_cells\n",
    "\n",
    "def make_arrays(spike_time_cells,trials_intervals):\n",
    "    spikes=[]\n",
    "    neurons=[]\n",
    "    trials=[]\n",
    "    trials_orig=trials_intervals*1000  \n",
    "    neurons_orig=range(len(spike_time_cells))\n",
    "    \n",
    "    for neuron in neurons_orig:\n",
    "        #spk_ids=spike_time_cells[neuron]\n",
    "        spk_tms_one_neuron=spike_time_cells[neuron]\n",
    "        for trial in range(0,260):\n",
    "            trial_range= np.bitwise_and(spk_tms_one_neuron>=trials_orig[trial][0],spk_tms_one_neuron<=trials_orig[trial][1])\n",
    "            if trial==0:\n",
    "                #trial_range= np.bitwise_and(spk_tms_one_neuron>=trials[trial][0],spk_tms_one_neuron<=trials[trial][1])\n",
    "                subset=spk_tms_one_neuron[trial_range]\n",
    "            else:\n",
    "                subset=spk_tms_one_neuron[trial_range]-trials_orig[trial-1][1]\n",
    "            for spike in subset:\n",
    "                trials.append(trial)\n",
    "                spikes.append(spike)\n",
    "                neurons.append(neuron)\n",
    "    return neurons,trials,spikes\n",
    "        \n",
    "    \n",
    "def preprocess_for_affine_warp(bin_size):\n",
    "    good_cells, brain_regions,br = get_good_cells(data_path) # Get brain regions\n",
    "    spike_time_cells=get_neurons(spike_times,spike_clusters)\n",
    "    neurons,trials,spikes=make_arrays(spike_time_cells,trials_intervals)\n",
    "    #neuron_trials=extract_trial_aligned(spike_time_cells,trials_intervals)\n",
    "    #mean_lst=bin_and_average(neuron_trials,trials_intervals,bin_size=10)\n",
    "    #dat_for_affine_warp= preprocess_for_affine_warp(neuron_trials,trials_intervals,bin_size=10)\n",
    "    #spike_time_binned, spike_time_cells, cell_spikes_max = bin_spikes(spike_times,spike_clusters,clusters_annotation,bin_size=bs)\n",
    "    return neurons,trials,spikes\n",
    "neurons,trials,spikes=preprocess_for_affine_warp(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553247\n"
     ]
    }
   ],
   "source": [
    "print(len(spikes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
