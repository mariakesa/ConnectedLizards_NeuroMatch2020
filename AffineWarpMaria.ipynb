{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affinewarp import PiecewiseWarping, SpikeData\n",
    "import numpy as np\n",
    "from affinewarp.visualization import rasters    \n",
    "import matplotlib.pyplot as plt\n",
    "from DataPreprocessing import *\n",
    "from DataPreprocessing import *\n",
    "import elephant.conversion as conv\n",
    "import neo\n",
    "import quantities as pq\n",
    "from elephant.statistics import instantaneous_rate,time_histogram\n",
    "import neo\n",
    "from elephant import kernels\n",
    "from quantities import Hz, s, ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_brain_circuits=['SCs','SCm','MRN','APN','PAG','ZI']\n",
    "frontal_circuits=['MOs','PL','ILA','ORB','MOp','SSp']\n",
    "all_data_path='/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss improvement: 5.83%: 100%|██████████| 50/50 [01:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "data_path= '/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files/Richards_2017-10-31.tar'\n",
    "\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load(data_path+'/'+'trials.goCue_times.npy') \n",
    "trials_response_choice = np.load(data_path+'/'+'trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load(data_path+'/'+'spontaneous.intervals.npy')\n",
    "trials_response_time = np.load(data_path+'/'+'trials.response_times.npy')\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "site_positions = np.load(data_path+'/'+'channels.sitePositions.npy')\n",
    "clusters_depths = np.load(data_path+'/'+'clusters.depths.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "channel_sites = np.load(data_path+'/'+'channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv(data_path+'/'+'channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load(data_path+'/'+'clusters.probes.npy')\n",
    "channels_probe = np.load(data_path+'/'+'channels.probe.npy')\n",
    "trials_visual_time = np.load(data_path+'/'+'trials.visualStim_times.npy')\n",
    "\n",
    "good_cells, brain_regions,br = get_good_cells(data_path) #\n",
    "#print(good_cells)\n",
    "\n",
    "def get_neurons(spike_times,spike_clusters):\n",
    "    spike_time_cells = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "    for i in range(len(np.unique(spike_clusters))):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == i)[0])]\n",
    "    return spike_time_cells\n",
    "\n",
    "def make_arrays(spike_time_cells,trials_intervals):\n",
    "    spikes=[]\n",
    "    neurons=[]\n",
    "    trials=[]\n",
    "    trials_orig=trials_intervals*1000  \n",
    "    neurons_orig=range(len(spike_time_cells))\n",
    "    \n",
    "    for neuron in neurons_orig:\n",
    "        #spk_ids=spike_time_cells[neuron]\n",
    "        spk_tms_one_neuron=spike_time_cells[neuron]\n",
    "        for trial in range(0,260):\n",
    "            trial_range= np.bitwise_and(spk_tms_one_neuron>=trials_orig[trial][0],spk_tms_one_neuron<=trials_orig[trial][1])\n",
    "            if trial==0:\n",
    "                #trial_range= np.bitwise_and(spk_tms_one_neuron>=trials[trial][0],spk_tms_one_neuron<=trials[trial][1])\n",
    "                subset=spk_tms_one_neuron[trial_range]\n",
    "            else:\n",
    "                subset=spk_tms_one_neuron[trial_range]-trials_orig[trial-1][1]\n",
    "            for spike in subset:\n",
    "                trials.append(trial)\n",
    "                spikes.append(spike)\n",
    "                neurons.append(neuron)\n",
    "    return neurons,trials,spikes\n",
    "\n",
    "def run_affinewarp(neurons,trials,spikes):\n",
    "    data = SpikeData(trials, spikes, neurons, tmin=0, tmax=1500)\n",
    "    binned = data.bin_spikes(n_bins=20)\n",
    "    from affinewarp import PiecewiseWarping\n",
    "    model = PiecewiseWarping()\n",
    "    model.fit(binned)\n",
    "    aligned_data = model.transform(data)\n",
    "    return aligned_data\n",
    "    \n",
    "    \n",
    "def preprocess_for_affine_warp(bin_size):\n",
    "    good_cells, brain_regions,br = get_good_cells(data_path) # Get brain regions\n",
    "    spike_time_cells=get_neurons(spike_times,spike_clusters)\n",
    "    #neurons,trials,spikes=make_arrays(spike_time_cells,trials_intervals)\n",
    "    #neuron_trials=extract_trial_aligned(spike_time_cells,trials_intervals)\n",
    "    neurons=np.load('neurons.npy')\n",
    "    trials=np.load('trials.npy')\n",
    "    spikes=np.load('spikes.npy')\n",
    "    aligned_data=run_affinewarp(neurons,trials,spikes)\n",
    "    #mean_lst=bin_and_average(neuron_trials,trials_intervals,bin_size=10)\n",
    "    #dat_for_affine_warp= preprocess_for_affine_warp(neuron_trials,trials_intervals,bin_size=10)\n",
    "    #spike_time_binned, spike_time_cells, cell_spikes_max = bin_spikes(spike_times,spike_clusters,clusters_annotation,bin_size=bs)\n",
    "    #return neurons,trials,spikes\n",
    "    return aligned_data\n",
    "aligned_data=preprocess_for_affine_warp(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553247\n"
     ]
    }
   ],
   "source": [
    "print(len(aligned_data.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([259, 259, 259, ..., 259, 259, 259])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials=aligned_data.trials\n",
    "trials[trials==259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[600]]\n",
      "[[1373]]\n",
      "[[295]]\n",
      "[[221]]\n",
      "[[635]]\n",
      "[[190]]\n",
      "[[249]]\n",
      "[[71]]\n",
      "[[183]]\n",
      "[[17]]\n",
      "[[241]]\n",
      "[[1221]]\n",
      "[[489]]\n",
      "[[195]]\n",
      "[[216]]\n",
      "[[707]]\n",
      "[[227]]\n",
      "[[38]]\n",
      "[[389]]\n",
      "[[218]]\n",
      "[[337]]\n",
      "[[1798]]\n",
      "[[375]]\n",
      "[[544]]\n",
      "[[49]]\n",
      "[[84]]\n",
      "[[105]]\n",
      "[[3500]]\n",
      "[[868]]\n",
      "[[179]]\n",
      "[[22]]\n",
      "[[64]]\n",
      "[[117]]\n",
      "[[1605]]\n",
      "[[158]]\n",
      "[[6]]\n",
      "[[130]]\n",
      "[[73]]\n",
      "[[2205]]\n",
      "[[622]]\n",
      "[[986]]\n",
      "[[47]]\n",
      "[[151]]\n",
      "[[542]]\n",
      "[[1288]]\n",
      "[[591]]\n",
      "[[27]]\n",
      "[[367]]\n",
      "[[2023]]\n",
      "[[169]]\n",
      "[[387]]\n",
      "[[314]]\n",
      "[[182]]\n",
      "[[94]]\n",
      "[[20]]\n",
      "[[110]]\n",
      "[[36]]\n",
      "[[57]]\n",
      "[[1518]]\n",
      "[[596]]\n",
      "[[212]]\n",
      "[[16]]\n",
      "[[1578]]\n",
      "[[1289]]\n",
      "[[133]]\n",
      "[[31]]\n",
      "[[427]]\n",
      "[[276]]\n",
      "[[93]]\n",
      "[[18]]\n",
      "[[225]]\n",
      "[[487]]\n",
      "[[31]]\n",
      "[[145]]\n",
      "[[1101]]\n",
      "[[645]]\n",
      "[[1483]]\n",
      "[[981]]\n",
      "[[621]]\n",
      "[[59]]\n",
      "[[392]]\n",
      "[[25]]\n",
      "[[1337]]\n",
      "[[877]]\n",
      "[[140]]\n",
      "[[450]]\n",
      "[[851]]\n",
      "[[839]]\n",
      "[[1210]]\n",
      "[[52]]\n",
      "[[1526]]\n",
      "[[40]]\n",
      "[[83]]\n",
      "[[158]]\n",
      "[[389]]\n",
      "[[1291]]\n",
      "[[613]]\n",
      "[[11]]\n",
      "[[70]]\n",
      "[[20]]\n",
      "[[1094]]\n",
      "[[289]]\n",
      "[[344]]\n",
      "[[320]]\n",
      "[[1152]]\n",
      "[[31]]\n",
      "[[525]]\n",
      "[[79]]\n",
      "[[47]]\n",
      "[[9]]\n",
      "[[103]]\n",
      "[[354]]\n",
      "[[848]]\n",
      "[[158]]\n",
      "[[286]]\n",
      "[[46]]\n",
      "[[285]]\n",
      "[[319]]\n",
      "[[354]]\n",
      "[[100]]\n",
      "[[3777]]\n",
      "[[185]]\n",
      "[[230]]\n",
      "[[128]]\n",
      "[[986]]\n",
      "[[750]]\n",
      "[[419]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Starting time of each spike train must be smaller than each stopping time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e0bed32308d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mav_tot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     '''\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mconvert_from_aligned_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-e0bed32308d9>\u001b[0m in \u001b[0;36mconvert_from_aligned_data\u001b[0;34m(aligned_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mspk_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpikeTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_neuron_spikes\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             binned_spk_tr = conv.BinnedSpikeTrain(spk_tr, binsize=0.02524578*pq.s,\n\u001b[0;32m---> 16\u001b[0;31m                                     t_start=start*pq.ms,t_stop=end*pq.ms)\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mbinned_spk_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinned_spk_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_spk_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elephant/conversion.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spiketrains, binsize, num_bins, t_start, t_stop)\u001b[0m\n\u001b[1;32m    435\u001b[0m             self.binsize, self.num_bins, self.t_start, self.t_stop)\n\u001b[1;32m    436\u001b[0m         self._check_consistency(spiketrains, self.binsize, self.num_bins,\n\u001b[0;32m--> 437\u001b[0;31m                                 self.t_start, self.t_stop)\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;31m# Now create sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_binned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiketrains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elephant/conversion.py\u001b[0m in \u001b[0;36m_check_consistency\u001b[0;34m(self, spiketrains, binsize, num_bins, t_start, t_stop)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mmin_tstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_stops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_tstart\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_tstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 raise ValueError(\"Starting time of each spike train must be \"\n\u001b[0m\u001b[1;32m    561\u001b[0m                                  \"smaller than each stopping time\")\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt_start\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_tstart\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt_start\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_tstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Starting time of each spike train must be smaller than each stopping time"
     ]
    }
   ],
   "source": [
    "def convert_from_aligned_data(aligned_data):\n",
    "    neurons=aligned_data.neurons\n",
    "    trials=aligned_data.trials\n",
    "    spikes=aligned_data.spiketimes\n",
    "    #mean_trials=[]\n",
    "    #trials_intervals=trials_intervals*1000\n",
    "    for neuron in range(0,np.unique(neurons).shape[0]):\n",
    "        one_neuron_trial=np.where(trials[neurons==neuron])[0]\n",
    "        one_neuron_spikes=spikes[one_neuron_trial]\n",
    "        #print(one_neuron_spikes)\n",
    "        if one_neuron_spikes!=[]:\n",
    "            start=np.min(one_neuron_spikes)\n",
    "            end=np.max(one_neuron_spikes)\n",
    "            spk_tr=neo.SpikeTrain(one_neuron_spikes*pq.ms,t_start=start*pq.ms,t_stop=end*pq.ms)\n",
    "            binned_spk_tr = conv.BinnedSpikeTrain(spk_tr, binsize=0.02524578*pq.s,\n",
    "                                    t_start=start*pq.ms,t_stop=end*pq.ms)\n",
    "            binned_spk_tr=binned_spk_tr.to_array()\n",
    "            print(binned_spk_tr)\n",
    "        \n",
    "        '''\n",
    "        for trial in range(260):\n",
    "            \n",
    "            spk_tr=neo.SpikeTrain(neuron_trials[neuron][trial]*pq.ms,t_start=start*pq.ms,t_stop=end*pq.ms)\n",
    "            binned_spk_tr = conv.BinnedSpikeTrain(spk_tr, binsize=0.02524578*pq.s,\n",
    "                                t_start=start*pq.ms,t_stop=end*pq.ms)\n",
    "            binned_spk_tr=binned_spk_tr.to_array()\n",
    "            print(binned_spk_tr.shape)\n",
    "            neuron_av.append(binned_spk_tr)\n",
    "        #neuron_av.append(np.mean(binned_spk_tr,axis=0))\n",
    "        mean_trials.append(neuron_av)\n",
    "        \n",
    "    minim=[]\n",
    "    for j in range(0,len(neuron_trials.keys())):\n",
    "        for i in range(0,trials_intervals.shape[0]):\n",
    "            minim.append(mean_lst[j][i].shape[1])\n",
    "    minimum=np.min(minim)\n",
    "\n",
    "    av_tot=[]\n",
    "    for j in range(0,len(neuron_trials.keys())):\n",
    "        av=[]\n",
    "        for i in range(0,trials_intervals.shape[0]):\n",
    "            av.append(mean_lst[j][i].flatten()[:minim])\n",
    "            #print(av[-1].shape)\n",
    "        av=np.array(av)\n",
    "        print(av.shape)\n",
    "        av_mean=np.mean(av,axis=0)\n",
    "        av_tot.append(av_mean)\n",
    "    av_tot=np.array(av_tot)\n",
    "            \n",
    "    return av_tot\n",
    "    '''\n",
    "convert_from_aligned_data(aligned_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
