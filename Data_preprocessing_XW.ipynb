{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os , csv\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load desired data from 1 session 1 animal\n",
    "# Note that there are 340 trials in 1 session\n",
    "# (For more info https://github.com/nsteinme/steinmetz-et-al-2019/wiki/data-files)\n",
    "\n",
    "data_path= '/Users/xinweichia/Documents/connected_lizards/Steinmetz_dataset/Richards_2017-10-31'\n",
    "\n",
    "os.chdir(data_path) # Change working directory\n",
    "\n",
    "trials_intervals = np.load('trials.intervals.npy') # in seconds\n",
    "spike_times = np.load('spikes.times.npy') * 1000 # Unbinned spike times in ms\n",
    "trials_gocue_times = np.load('trials.goCue_times.npy') \n",
    "trials_response_choice = np.load('trials.response_choice.npy') # -1 left, 1, right, 0 no response\n",
    "spontaneous_intervals = np.load('spontaneous.intervals.npy')\n",
    "trials_response_time = np.load('trials.response_times.npy')\n",
    "spike_clusters = np.load('spikes.clusters.npy')\n",
    "site_positions = np.load('channels.sitePositions.npy')\n",
    "clusters_depths = np.load('clusters.depths.npy')\n",
    "clusters_annotation = np.load('clusters._phy_annotation.npy')\n",
    "channel_sites = np.load('channels.site.npy')\n",
    "channels_brainlocation = pd.read_csv('channels.brainLocation.tsv', sep='\\t')\n",
    "clusters_probes = np.load('clusters.probes.npy')\n",
    "channels_probe = np.load('channels.probe.npy')\n",
    "trials_visual_time = np.load('trials.visualStim_times.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/MouseLand/steinmetz2019_NMA/blob/master/steinmetz_loader.py\n",
    "# To obtain brain regions\n",
    "def get_good_cells(fdirpath): #\n",
    "    # location in brain of each neuron\n",
    "    brain_loc = os.path.join(fdirpath, \"channels.brainLocation.tsv\")\n",
    "\n",
    "    good_cells = (np.load(os.path.join(fdirpath, \"clusters._phy_annotation.npy\")) >= 2 ).flatten()\n",
    "    clust_channel = np.load(os.path.join(fdirpath, \"clusters.peakChannel.npy\")).astype(int) - 1\n",
    "    br = []\n",
    "    with open(brain_loc, 'r') as tsv:\n",
    "        tsvin = csv.reader(tsv, delimiter=\"\\t\")\n",
    "        k=0\n",
    "        for row in tsvin:\n",
    "            if k>0:\n",
    "                br.append(row[-1])\n",
    "            k+=1\n",
    "    br = np.array(br)\n",
    "    good_cells = np.logical_and(good_cells, clust_channel.flatten()<len(br))\n",
    "    brain_region = br[clust_channel[:,0]]\n",
    "\n",
    "\n",
    "    return good_cells, brain_region, br\n",
    "\n",
    "good_cells, brain_regions ,br = get_good_cells('') # Get brain regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin cells according to input bin size\n",
    "\n",
    "def bin_spikes(spike_times, clusters_annotation , bin_size = 10):\n",
    "    \n",
    "    # Using clusters._phy_annotation.npy obtain valid clusters (i.e. >= 2)\n",
    "    valid_clusters_idx = np.array(np.where(clusters_annotation>=2))[0]\n",
    "\n",
    "    spike_time_cells = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    for i,cell_idx in enumerate(valid_clusters_idx):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == cell_idx)[0])]\n",
    "\n",
    "    # Bin spike times into 10ms intervals\n",
    "    spike_time_binned = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "    sum_spikes = np.empty(len(valid_clusters_idx), dtype=object) # Initalise empty object\n",
    "\n",
    "    for cell_num in np.arange(len(spike_time_cells)): \n",
    "        spike_time_hist = np.histogram(spike_time_cells[cell_num],bins = np.arange(0,np.floor(spike_time_cells[cell_num][-1]),bin_size))\n",
    "        spike_time_binned[cell_num] = spike_time_hist[0]\n",
    "        sum_spikes[cell_num] = np.sum(spike_time_binned[cell_num])\n",
    "\n",
    "    cell_spikes_max = np.argmax(sum_spikes) # cell with the maximum number of spikes for plotting purposes\n",
    "    \n",
    "    # Spike_time_binned returns binned spikes sorted into cells\n",
    "    # Spike_time_cells returns UNbinned spikes sorted into cells\n",
    "    # cell_spikes_max returns a single cell index that has the max number of spikes (i.e most active cell)\n",
    "    return spike_time_binned, spike_time_cells, cell_spikes_max\n",
    "\n",
    "spike_time_binned, spike_time_cells, cell_spikes_max = bin_spikes(spike_times, clusters_annotation,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cells into trial types and relevant epoch\n",
    "\n",
    "def sort_cells_trials(spike_time_binned, trials_visual_time, epoch_duration  = 400):\n",
    "\n",
    "    # Epoch duration is defined as the period after the visual stimulus\n",
    "\n",
    "    # Sort into trials\n",
    "    spike_time_binned_trial = np.empty(len(spike_time_cells), dtype=object)\n",
    "    spike_time_binned_trial_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        spike_time_binned_trial[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "        spike_time_binned_trial_response[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "  \n",
    "        for i,trials_start_end in enumerate(trials_intervals):\n",
    "            # Sort spikes into their trial numbers. \n",
    "            spike_time_binned_trial[cell_num][i] = spike_time_binned[cell_num][ int(np.floor(trials_start_end[0]*100)) : int(np.floor(trials_start_end[1]*100))]\n",
    "            # Using visual onset to splice a trial into visual onset : visual onset +400ms\n",
    "            spike_time_binned_trial_response[cell_num][i] = spike_time_binned[cell_num][(int(np.floor(trials_visual_time[i]*100))) : (int(np.floor(trials_visual_time[i]*100) + epoch_duration))]\n",
    "\n",
    "    # spike_time_binned_trial returns spikes that are sorted into cells and trials\n",
    "    # spike_time_binned_trial_response returns spikes that are sorted into cells and trials, and spliced accordingly to desired epoch duration post-visual stim onset\n",
    "    \n",
    "    return spike_time_binned_trial, spike_time_binned_trial_response\n",
    "\n",
    "spike_time_binned_trial, spike_time_binned_trial_response = sort_cells_trials(spike_time_binned, trials_visual_time,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort trials into 3 trial types based on argument (e.g. response_choice, feedback type), left, \n",
    "\n",
    "def sort_cells_trial_types(spike_time_binned_trial_response ,trials_response_choice):\n",
    "\n",
    "    # Input: spike_time_binned_trial_response can be any spike_time_binned variable regardless of whether it has been spliced.\n",
    "\n",
    "    # Get response choice trials types\n",
    "    right_choice_trials = np.where(trials_response_choice == -1)[0]\n",
    "    left_choice_trials = np.where(trials_response_choice == 1)[0]\n",
    "    no_response_choice_trials = np.where(trials_response_choice == 0)[0]\n",
    "\n",
    "    # Sort trials into response type\n",
    "    left_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    right_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    no_response_spike_time_response = np.empty(len(spike_time_cells), dtype=object)\n",
    "    \n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        left_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][left_choice_trials]\n",
    "        right_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][right_choice_trials]\n",
    "        no_response_spike_time_response[cell_num] = spike_time_binned_trial_response[cell_num][no_response_choice_trials]\n",
    "    \n",
    "    # Returns 3 variables by sorting the spike_time_binned variable into left, right no response trials\n",
    "    return left_spike_time_response, right_spike_time_response, no_response_spike_time_response\n",
    "\n",
    "left_spike_time_response, right_spike_time_response, no_response_spike_time_response = sort_cells_trial_types(spike_time_binned_trial_response ,trials_response_choice)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226,)\n"
     ]
    }
   ],
   "source": [
    "# Sort cells into input brain regions and merge them across all regions\n",
    "\n",
    "def sort_cells_brain_regions(spike_time_response, *input_region):\n",
    "    \n",
    "    regional_spike_time_response = np.empty(len(input_region), dtype=object)\n",
    "    for i,region in enumerate(input_region):\n",
    "        # Get brain regions that correponds to the desired region\n",
    "        brain_region_annotation = clusters_annotation[brain_regions == region]\n",
    "        # Select only valid regions i.e. annotation >=2\n",
    "        valid_brain_regions_idx = np.where(brain_region_annotation >= 2)[0]\n",
    "        # Index the spike time to get spikes from desired regions\n",
    "        regional_spike_time_response[i] = spike_time_response[valid_brain_regions_idx]\n",
    "    \n",
    "    # Merge spikes across all regions\n",
    "    merged_region_spikes = []\n",
    "    for i in np.arange(len(regional_spike_time_response)):\n",
    "        merged_region_spikes = np.append(merged_region_spikes, regional_spike_time_response[i])\n",
    "    \n",
    "    # Return spike time sorted into regions and merged across all regions\n",
    "    return merged_region_spikes\n",
    "\n",
    "regional_left_spike = sort_cells_brain_regions(left_spike_time_response, 'SCs','ORB','VISp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
